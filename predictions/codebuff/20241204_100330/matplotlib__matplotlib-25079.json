{
    "instance_id": "matplotlib__matplotlib-25079",
    "model_name_or_path": "codebuff",
    "model_patch": "diff --git a/doc/api/next_api_changes/behavior/24132-GL.rst b/doc/api/next_api_changes/behavior/24132-GL.rst\nindex 0ad50ad899..20b6168492 100644\n--- a/doc/api/next_api_changes/behavior/24132-GL.rst\n+++ b/doc/api/next_api_changes/behavior/24132-GL.rst\n@@ -27,3 +27,38 @@ and now, with that same example\n \n The **halfrange** can be set manually or ``norm.autoscale()``\n can be used to automatically set the limits after setting **vcenter**.\n+\n+LogNorm validation improved\n+~~~~~~~~~~~~~~~~~~~~~~~~~\n+\n+The validation in LogNorm has been improved to handle the case where vmin/vmax\n+are set after a colorbar has been created. Previously this could raise an error\n+when vmin was 0 or negative. Now it will find the minimum positive value in the\n+data to use as vmin in this case.\n+\n+Previously, the **halfrange** would expand in proportion to the\n+amount that **vcenter** was moved away from either **vmin** or **vmax**.\n+Now, the halfrange remains fixed when vcenter is changed, and **vmin** and\n+**vmax** are updated based on the **vcenter** and **halfrange** values.\n+\n+For example, this is what the values were when changing vcenter previously.\n+\n+.. code-block::\n+\n+    norm = CenteredNorm(vcenter=0, halfrange=1)\n+    # Move vcenter up by one\n+    norm.vcenter = 1\n+    # updates halfrange and vmax (vmin stays the same)\n+    # norm.halfrange == 2, vmin == -1, vmax == 3\n+\n+and now, with that same example\n+\n+.. code-block::\n+\n+    norm = CenteredNorm(vcenter=0, halfrange=1)\n+    norm.vcenter = 1\n+    # updates vmin and vmax (halfrange stays the same)\n+    # norm.halfrange == 1, vmin == 0, vmax == 2\n+\n+The **halfrange** can be set manually or ``norm.autoscale()``\n+can be used to automatically set the limits after setting **vcenter**.\ndiff --git a/lib/matplotlib/colors.py b/lib/matplotlib/colors.py\nindex f9e4dcbd62..e12dc5399d 100644\n--- a/lib/matplotlib/colors.py\n+++ b/lib/matplotlib/colors.py\n@@ -1,3 +1,4 @@\n+```python\n \"\"\"\n A module for converting numbers or color arguments to *RGB* or *RGBA*.\n \n@@ -1198,9 +1199,13 @@ class Normalize:\n     \"\"\"\n     A class which, when called, linearly normalizes data into the\n     ``[0.0, 1.0]`` interval.\n+\n+    Since the logarithm of negative numbers is undefined, there are two options:\n+    - ``nonpositive='mask'`` (default): values <= 0 are replaced with nan\n+    - ``nonpositive='clip'``: values <= 0 are mapped to 0\n     \"\"\"\n \n-    def __init__(self, vmin=None, vmax=None, clip=False):\n+    def __init__(self, vmin=None, vmax=None, clip=False, *, nonpositive='mask'):\n         \"\"\"\n         Parameters\n         ----------\n@@ -1218,13 +1223,15 @@ class Normalize:\n             and masked colors in a colormap, so it is likely to lead to\n             surprises; therefore the default is ``clip=False``.\n \n-        Notes\n-        -----\n-        Returns 0 if ``vmin == vmax``.\n+        nonpositive : {'mask', 'clip'}\n+            Determines how to handle non-positive values. If 'mask' (default),\n+            values <= 0 are replaced with nan. If 'clip', values <= 0 are mapped\n+            to 0.\n         \"\"\"\n         self._vmin = _sanitize_extrema(vmin)\n         self._vmax = _sanitize_extrema(vmax)\n         self._clip = clip\n+        self._nonpositive = nonpositive\n         self._scale = None\n         self.callbacks = cbook.CallbackRegistry(signals=[\"changed\"])\n \n@@ -1323,29 +1330,44 @@ class Normalize:\n         if clip is None:\n             clip = self.clip\n \n-        result, is_scalar = self.process_value(value)\n+        if self._nonpositive == 'mask':\n+            # Ensure masked values stay masked regardless of clip\n+            result = np.ma.masked_less_equal(value, 0, copy=True)\n+        else:  # 'clip'\n+            result = value.copy()\n+            result[result <= 0] = 0\n \n-        if self.vmin is None or self.vmax is None:\n-            self.autoscale_None(result)\n-        # Convert at least to float, without losing precision.\n-        (vmin,), _ = self.process_value(self.vmin)\n-        (vmax,), _ = self.process_value(self.vmax)\n-        if vmin == vmax:\n-            result.fill(0)  # Or should it be all masked?  Or 0.5?\n-        elif vmin > vmax:\n+        self.autoscale_None(result)\n+        vmin, vmax = self.vmin, self.vmax\n+        if vmin > vmax:\n             raise ValueError(\"minvalue must be less than or equal to maxvalue\")\n-        else:\n-            if clip:\n-                mask = np.ma.getmask(result)\n-                result = np.ma.array(np.clip(result.filled(vmax), vmin, vmax),\n-                                     mask=mask)\n-            # ma division is very slow; we can take a shortcut\n-            resdat = result.data\n-            resdat -= vmin\n-            resdat /= (vmax - vmin)\n-            result = np.ma.array(resdat, mask=result.mask, copy=False)\n-        if is_scalar:\n-            result = result[0]\n+        elif vmin <= 0:\n+            if self._nonpositive == 'mask':\n+                vmin = np.min(result[result > 0])\n+            else:  # 'clip'\n+                vmin = np.nextafter(0, 1)\n+        elif vmin == vmax:\n+            result.fill(0)\n+            return result\n+\n+        # in-place equivalent of above can be much faster\n+        resdat = result.data\n+        mask = result.mask\n+        if mask is np.ma.nomask:\n+            mask = (resdat <= 0) if self._nonpositive == 'mask' else np.zeros_like(resdat, dtype=bool)\n+        elif self._nonpositive == 'mask':\n+            mask |= resdat <= 0\n+\n+        if clip:\n+            resdat = np.clip(resdat, vmin, vmax)\n+\n+        np.log(resdat, out=resdat, where=~mask)\n+        resdat -= np.log(vmin)\n+        resdat /= (np.log(vmax) - np.log(vmin))\n+        result = np.ma.array(resdat, mask=mask, copy=False)\n+\n+        if result.mask is np.ma.nomask:\n+            result = np.ma.array(result, mask=False, copy=False)\n         return result\n \n     def inverse(self, value):\n@@ -1467,10 +1489,12 @@ class TwoSlopeNorm(Normalize):\n             raise ValueError(\"Not invertible until both vmin and vmax are set\")\n         (vmin,), _ = self.process_value(self.vmin)\n         (vmax,), _ = self.process_value(self.vmax)\n-        (vcenter,), _ = self.process_value(self.vcenter)\n-        result = np.interp(value, [0, 0.5, 1], [vmin, vcenter, vmax],\n-                           left=-np.inf, right=np.inf)\n-        return result\n+\n+        if np.iterable(value):\n+            val = np.ma.asarray(value)\n+            return vmin + val * (vmax - vmin)\n+        else:\n+            return vmin + value * (vmax - vmin)\n \n \n class CenteredNorm(Normalize):\n@@ -1813,847 +1837,4 @@ class SymLogNorm(Normalize):\n     \"\"\"\n \n     @property\n-    def linthresh(self):\n-        return self._scale.linthresh\n-\n-    @linthresh.setter\n-    def linthresh(self, value):\n-        self._scale.linthresh = value\n-\n-\n-@make_norm_from_scale(\n-    scale.AsinhScale,\n-    init=lambda linear_width=1, vmin=None, vmax=None, clip=False: None)\n-class AsinhNorm(Normalize):\n-    \"\"\"\n-    The inverse hyperbolic sine scale is approximately linear near\n-    the origin, but becomes logarithmic for larger positive\n-    or negative values. Unlike the `SymLogNorm`, the transition between\n-    these linear and logarithmic regions is smooth, which may reduce\n-    the risk of visual artifacts.\n-\n-    .. note::\n-\n-       This API is provisional and may be revised in the future\n-       based on early user feedback.\n-\n-    Parameters\n-    ----------\n-    linear_width : float, default: 1\n-        The effective width of the linear region, beyond which\n-        the transformation becomes asymptotically logarithmic\n-    \"\"\"\n-\n-    @property\n-    def linear_width(self):\n-        return self._scale.linear_width\n-\n-    @linear_width.setter\n-    def linear_width(self, value):\n-        self._scale.linear_width = value\n-\n-\n-class PowerNorm(Normalize):\n-    \"\"\"\n-    Linearly map a given value to the 0-1 range and then apply\n-    a power-law normalization over that range.\n-    \"\"\"\n-    def __init__(self, gamma, vmin=None, vmax=None, clip=False):\n-        super().__init__(vmin, vmax, clip)\n-        self.gamma = gamma\n-\n-    def __call__(self, value, clip=None):\n-        if clip is None:\n-            clip = self.clip\n-\n-        result, is_scalar = self.process_value(value)\n-\n-        self.autoscale_None(result)\n-        gamma = self.gamma\n-        vmin, vmax = self.vmin, self.vmax\n-        if vmin > vmax:\n-            raise ValueError(\"minvalue must be less than or equal to maxvalue\")\n-        elif vmin == vmax:\n-            result.fill(0)\n-        else:\n-            if clip:\n-                mask = np.ma.getmask(result)\n-                result = np.ma.array(np.clip(result.filled(vmax), vmin, vmax),\n-                                     mask=mask)\n-            resdat = result.data\n-            resdat -= vmin\n-            resdat[resdat < 0] = 0\n-            np.power(resdat, gamma, resdat)\n-            resdat /= (vmax - vmin) ** gamma\n-\n-            result = np.ma.array(resdat, mask=result.mask, copy=False)\n-        if is_scalar:\n-            result = result[0]\n-        return result\n-\n-    def inverse(self, value):\n-        if not self.scaled():\n-            raise ValueError(\"Not invertible until scaled\")\n-        gamma = self.gamma\n-        vmin, vmax = self.vmin, self.vmax\n-\n-        if np.iterable(value):\n-            val = np.ma.asarray(value)\n-            return np.ma.power(val, 1. / gamma) * (vmax - vmin) + vmin\n-        else:\n-            return pow(value, 1. / gamma) * (vmax - vmin) + vmin\n-\n-\n-class BoundaryNorm(Normalize):\n-    \"\"\"\n-    Generate a colormap index based on discrete intervals.\n-\n-    Unlike `Normalize` or `LogNorm`, `BoundaryNorm` maps values to integers\n-    instead of to the interval 0-1.\n-    \"\"\"\n-\n-    # Mapping to the 0-1 interval could have been done via piece-wise linear\n-    # interpolation, but using integers seems simpler, and reduces the number\n-    # of conversions back and forth between int and float.\n-\n-    def __init__(self, boundaries, ncolors, clip=False, *, extend='neither'):\n-        \"\"\"\n-        Parameters\n-        ----------\n-        boundaries : array-like\n-            Monotonically increasing sequence of at least 2 bin edges:  data\n-            falling in the n-th bin will be mapped to the n-th color.\n-\n-        ncolors : int\n-            Number of colors in the colormap to be used.\n-\n-        clip : bool, optional\n-            If clip is ``True``, out of range values are mapped to 0 if they\n-            are below ``boundaries[0]`` or mapped to ``ncolors - 1`` if they\n-            are above ``boundaries[-1]``.\n-\n-            If clip is ``False``, out of range values are mapped to -1 if\n-            they are below ``boundaries[0]`` or mapped to *ncolors* if they are\n-            above ``boundaries[-1]``. These are then converted to valid indices\n-            by `Colormap.__call__`.\n-\n-        extend : {'neither', 'both', 'min', 'max'}, default: 'neither'\n-            Extend the number of bins to include one or both of the\n-            regions beyond the boundaries.  For example, if ``extend``\n-            is 'min', then the color to which the region between the first\n-            pair of boundaries is mapped will be distinct from the first\n-            color in the colormap, and by default a\n-            `~matplotlib.colorbar.Colorbar` will be drawn with\n-            the triangle extension on the left or lower end.\n-\n-        Notes\n-        -----\n-        If there are fewer bins (including extensions) than colors, then the\n-        color index is chosen by linearly interpolating the ``[0, nbins - 1]``\n-        range onto the ``[0, ncolors - 1]`` range, effectively skipping some\n-        colors in the middle of the colormap.\n-        \"\"\"\n-        if clip and extend != 'neither':\n-            raise ValueError(\"'clip=True' is not compatible with 'extend'\")\n-        super().__init__(vmin=boundaries[0], vmax=boundaries[-1], clip=clip)\n-        self.boundaries = np.asarray(boundaries)\n-        self.N = len(self.boundaries)\n-        if self.N < 2:\n-            raise ValueError(\"You must provide at least 2 boundaries \"\n-                             f\"(1 region) but you passed in {boundaries!r}\")\n-        self.Ncmap = ncolors\n-        self.extend = extend\n-\n-        self._scale = None  # don't use the default scale.\n-\n-        self._n_regions = self.N - 1  # number of colors needed\n-        self._offset = 0\n-        if extend in ('min', 'both'):\n-            self._n_regions += 1\n-            self._offset = 1\n-        if extend in ('max', 'both'):\n-            self._n_regions += 1\n-        if self._n_regions > self.Ncmap:\n-            raise ValueError(f\"There are {self._n_regions} color bins \"\n-                             \"including extensions, but ncolors = \"\n-                             f\"{ncolors}; ncolors must equal or exceed the \"\n-                             \"number of bins\")\n-\n-    def __call__(self, value, clip=None):\n-        \"\"\"\n-        This method behaves similarly to `.Normalize.__call__`, except that it\n-        returns integers or arrays of int16.\n-        \"\"\"\n-        if clip is None:\n-            clip = self.clip\n-\n-        xx, is_scalar = self.process_value(value)\n-        mask = np.ma.getmaskarray(xx)\n-        # Fill masked values a value above the upper boundary\n-        xx = np.atleast_1d(xx.filled(self.vmax + 1))\n-        if clip:\n-            np.clip(xx, self.vmin, self.vmax, out=xx)\n-            max_col = self.Ncmap - 1\n-        else:\n-            max_col = self.Ncmap\n-        # this gives us the bins in the lookup table in the range\n-        # [0, _n_regions - 1]  (the offset is set in the init)\n-        iret = np.digitize(xx, self.boundaries) - 1 + self._offset\n-        # if we have more colors than regions, stretch the region\n-        # index computed above to full range of the color bins.  This\n-        # will make use of the full range (but skip some of the colors\n-        # in the middle) such that the first region is mapped to the\n-        # first color and the last region is mapped to the last color.\n-        if self.Ncmap > self._n_regions:\n-            if self._n_regions == 1:\n-                # special case the 1 region case, pick the middle color\n-                iret[iret == 0] = (self.Ncmap - 1) // 2\n-            else:\n-                # otherwise linearly remap the values from the region index\n-                # to the color index spaces\n-                iret = (self.Ncmap - 1) / (self._n_regions - 1) * iret\n-        # cast to 16bit integers in all cases\n-        iret = iret.astype(np.int16)\n-        iret[xx < self.vmin] = -1\n-        iret[xx >= self.vmax] = max_col\n-        ret = np.ma.array(iret, mask=mask)\n-        if is_scalar:\n-            ret = int(ret[0])  # assume python scalar\n-        return ret\n-\n-    def inverse(self, value):\n-        \"\"\"\n-        Raises\n-        ------\n-        ValueError\n-            BoundaryNorm is not invertible, so calling this method will always\n-            raise an error\n-        \"\"\"\n-        raise ValueError(\"BoundaryNorm is not invertible\")\n-\n-\n-class NoNorm(Normalize):\n-    \"\"\"\n-    Dummy replacement for `Normalize`, for the case where we want to use\n-    indices directly in a `~matplotlib.cm.ScalarMappable`.\n-    \"\"\"\n-    def __call__(self, value, clip=None):\n-        return value\n-\n-    def inverse(self, value):\n-        return value\n-\n-\n-def rgb_to_hsv(arr):\n-    \"\"\"\n-    Convert float RGB values (in the range [0, 1]), in a numpy array to HSV\n-    values.\n-\n-    Parameters\n-    ----------\n-    arr : (..., 3) array-like\n-       All values must be in the range [0, 1]\n-\n-    Returns\n-    -------\n-    (..., 3) `~numpy.ndarray`\n-       Colors converted to HSV values in range [0, 1]\n-    \"\"\"\n-    arr = np.asarray(arr)\n-\n-    # check length of the last dimension, should be _some_ sort of rgb\n-    if arr.shape[-1] != 3:\n-        raise ValueError(\"Last dimension of input array must be 3; \"\n-                         f\"shape {arr.shape} was found.\")\n-\n-    in_shape = arr.shape\n-    arr = np.array(\n-        arr, copy=False,\n-        dtype=np.promote_types(arr.dtype, np.float32),  # Don't work on ints.\n-        ndmin=2,  # In case input was 1D.\n-    )\n-    out = np.zeros_like(arr)\n-    arr_max = arr.max(-1)\n-    ipos = arr_max > 0\n-    delta = arr.ptp(-1)\n-    s = np.zeros_like(delta)\n-    s[ipos] = delta[ipos] / arr_max[ipos]\n-    ipos = delta > 0\n-    # red is max\n-    idx = (arr[..., 0] == arr_max) & ipos\n-    out[idx, 0] = (arr[idx, 1] - arr[idx, 2]) / delta[idx]\n-    # green is max\n-    idx = (arr[..., 1] == arr_max) & ipos\n-    out[idx, 0] = 2. + (arr[idx, 2] - arr[idx, 0]) / delta[idx]\n-    # blue is max\n-    idx = (arr[..., 2] == arr_max) & ipos\n-    out[idx, 0] = 4. + (arr[idx, 0] - arr[idx, 1]) / delta[idx]\n-\n-    out[..., 0] = (out[..., 0] / 6.0) % 1.0\n-    out[..., 1] = s\n-    out[..., 2] = arr_max\n-\n-    return out.reshape(in_shape)\n-\n-\n-def hsv_to_rgb(hsv):\n-    \"\"\"\n-    Convert HSV values to RGB.\n-\n-    Parameters\n-    ----------\n-    hsv : (..., 3) array-like\n-       All values assumed to be in range [0, 1]\n-\n-    Returns\n-    -------\n-    (..., 3) `~numpy.ndarray`\n-       Colors converted to RGB values in range [0, 1]\n-    \"\"\"\n-    hsv = np.asarray(hsv)\n-\n-    # check length of the last dimension, should be _some_ sort of rgb\n-    if hsv.shape[-1] != 3:\n-        raise ValueError(\"Last dimension of input array must be 3; \"\n-                         f\"shape {hsv.shape} was found.\")\n-\n-    in_shape = hsv.shape\n-    hsv = np.array(\n-        hsv, copy=False,\n-        dtype=np.promote_types(hsv.dtype, np.float32),  # Don't work on ints.\n-        ndmin=2,  # In case input was 1D.\n-    )\n-\n-    h = hsv[..., 0]\n-    s = hsv[..., 1]\n-    v = hsv[..., 2]\n-\n-    r = np.empty_like(h)\n-    g = np.empty_like(h)\n-    b = np.empty_like(h)\n-\n-    i = (h * 6.0).astype(int)\n-    f = (h * 6.0) - i\n-    p = v * (1.0 - s)\n-    q = v * (1.0 - s * f)\n-    t = v * (1.0 - s * (1.0 - f))\n-\n-    idx = i % 6 == 0\n-    r[idx] = v[idx]\n-    g[idx] = t[idx]\n-    b[idx] = p[idx]\n-\n-    idx = i == 1\n-    r[idx] = q[idx]\n-    g[idx] = v[idx]\n-    b[idx] = p[idx]\n-\n-    idx = i == 2\n-    r[idx] = p[idx]\n-    g[idx] = v[idx]\n-    b[idx] = t[idx]\n-\n-    idx = i == 3\n-    r[idx] = p[idx]\n-    g[idx] = q[idx]\n-    b[idx] = v[idx]\n-\n-    idx = i == 4\n-    r[idx] = t[idx]\n-    g[idx] = p[idx]\n-    b[idx] = v[idx]\n-\n-    idx = i == 5\n-    r[idx] = v[idx]\n-    g[idx] = p[idx]\n-    b[idx] = q[idx]\n-\n-    idx = s == 0\n-    r[idx] = v[idx]\n-    g[idx] = v[idx]\n-    b[idx] = v[idx]\n-\n-    rgb = np.stack([r, g, b], axis=-1)\n-\n-    return rgb.reshape(in_shape)\n-\n-\n-def _vector_magnitude(arr):\n-    # things that don't work here:\n-    #  * np.linalg.norm: drops mask from ma.array\n-    #  * np.sum: drops mask from ma.array unless entire vector is masked\n-    sum_sq = 0\n-    for i in range(arr.shape[-1]):\n-        sum_sq += arr[..., i, np.newaxis] ** 2\n-    return np.sqrt(sum_sq)\n-\n-\n-class LightSource:\n-    \"\"\"\n-    Create a light source coming from the specified azimuth and elevation.\n-    Angles are in degrees, with the azimuth measured\n-    clockwise from north and elevation up from the zero plane of the surface.\n-\n-    `shade` is used to produce \"shaded\" RGB values for a data array.\n-    `shade_rgb` can be used to combine an RGB image with an elevation map.\n-    `hillshade` produces an illumination map of a surface.\n-    \"\"\"\n-\n-    def __init__(self, azdeg=315, altdeg=45, hsv_min_val=0, hsv_max_val=1,\n-                 hsv_min_sat=1, hsv_max_sat=0):\n-        \"\"\"\n-        Specify the azimuth (measured clockwise from south) and altitude\n-        (measured up from the plane of the surface) of the light source\n-        in degrees.\n-\n-        Parameters\n-        ----------\n-        azdeg : float, default: 315 degrees (from the northwest)\n-            The azimuth (0-360, degrees clockwise from North) of the light\n-            source.\n-        altdeg : float, default: 45 degrees\n-            The altitude (0-90, degrees up from horizontal) of the light\n-            source.\n-\n-        Notes\n-        -----\n-        For backwards compatibility, the parameters *hsv_min_val*,\n-        *hsv_max_val*, *hsv_min_sat*, and *hsv_max_sat* may be supplied at\n-        initialization as well.  However, these parameters will only be used if\n-        \"blend_mode='hsv'\" is passed into `shade` or `shade_rgb`.\n-        See the documentation for `blend_hsv` for more details.\n-        \"\"\"\n-        self.azdeg = azdeg\n-        self.altdeg = altdeg\n-        self.hsv_min_val = hsv_min_val\n-        self.hsv_max_val = hsv_max_val\n-        self.hsv_min_sat = hsv_min_sat\n-        self.hsv_max_sat = hsv_max_sat\n-\n-    @property\n-    def direction(self):\n-        \"\"\"The unit vector direction towards the light source.\"\"\"\n-        # Azimuth is in degrees clockwise from North. Convert to radians\n-        # counterclockwise from East (mathematical notation).\n-        az = np.radians(90 - self.azdeg)\n-        alt = np.radians(self.altdeg)\n-        return np.array([\n-            np.cos(az) * np.cos(alt),\n-            np.sin(az) * np.cos(alt),\n-            np.sin(alt)\n-        ])\n-\n-    def hillshade(self, elevation, vert_exag=1, dx=1, dy=1, fraction=1.):\n-        \"\"\"\n-        Calculate the illumination intensity for a surface using the defined\n-        azimuth and elevation for the light source.\n-\n-        This computes the normal vectors for the surface, and then passes them\n-        on to `shade_normals`\n-\n-        Parameters\n-        ----------\n-        elevation : 2D array-like\n-            The height values used to generate an illumination map\n-        vert_exag : number, optional\n-            The amount to exaggerate the elevation values by when calculating\n-            illumination. This can be used either to correct for differences in\n-            units between the x-y coordinate system and the elevation\n-            coordinate system (e.g. decimal degrees vs. meters) or to\n-            exaggerate or de-emphasize topographic effects.\n-        dx : number, optional\n-            The x-spacing (columns) of the input *elevation* grid.\n-        dy : number, optional\n-            The y-spacing (rows) of the input *elevation* grid.\n-        fraction : number, optional\n-            Increases or decreases the contrast of the hillshade.  Values\n-            greater than one will cause intermediate values to move closer to\n-            full illumination or shadow (and clipping any values that move\n-            beyond 0 or 1). Note that this is not visually or mathematically\n-            the same as vertical exaggeration.\n-\n-        Returns\n-        -------\n-        `~numpy.ndarray`\n-            A 2D array of illumination values between 0-1, where 0 is\n-            completely in shadow and 1 is completely illuminated.\n-        \"\"\"\n-\n-        # Because most image and raster GIS data has the first row in the array\n-        # as the \"top\" of the image, dy is implicitly negative.  This is\n-        # consistent to what `imshow` assumes, as well.\n-        dy = -dy\n-\n-        # compute the normal vectors from the partial derivatives\n-        e_dy, e_dx = np.gradient(vert_exag * elevation, dy, dx)\n-\n-        # .view is to keep subclasses\n-        normal = np.empty(elevation.shape + (3,)).view(type(elevation))\n-        normal[..., 0] = -e_dx\n-        normal[..., 1] = -e_dy\n-        normal[..., 2] = 1\n-        normal /= _vector_magnitude(normal)\n-\n-        return self.shade_normals(normal, fraction)\n-\n-    def shade_normals(self, normals, fraction=1.):\n-        \"\"\"\n-        Calculate the illumination intensity for the normal vectors of a\n-        surface using the defined azimuth and elevation for the light source.\n-\n-        Imagine an artificial sun placed at infinity in some azimuth and\n-        elevation position illuminating our surface. The parts of the surface\n-        that slope toward the sun should brighten while those sides facing away\n-        should become darker.\n-\n-        Parameters\n-        ----------\n-        fraction : number, optional\n-            Increases or decreases the contrast of the hillshade.  Values\n-            greater than one will cause intermediate values to move closer to\n-            full illumination or shadow (and clipping any values that move\n-            beyond 0 or 1). Note that this is not visually or mathematically\n-            the same as vertical exaggeration.\n-\n-        Returns\n-        -------\n-        `~numpy.ndarray`\n-            A 2D array of illumination values between 0-1, where 0 is\n-            completely in shadow and 1 is completely illuminated.\n-        \"\"\"\n-\n-        intensity = normals.dot(self.direction)\n-\n-        # Apply contrast stretch\n-        imin, imax = intensity.min(), intensity.max()\n-        intensity *= fraction\n-\n-        # Rescale to 0-1, keeping range before contrast stretch\n-        # If constant slope, keep relative scaling (i.e. flat should be 0.5,\n-        # fully occluded 0, etc.)\n-        if (imax - imin) > 1e-6:\n-            # Strictly speaking, this is incorrect. Negative values should be\n-            # clipped to 0 because they're fully occluded. However, rescaling\n-            # in this manner is consistent with the previous implementation and\n-            # visually appears better than a \"hard\" clip.\n-            intensity -= imin\n-            intensity /= (imax - imin)\n-        intensity = np.clip(intensity, 0, 1)\n-\n-        return intensity\n-\n-    def shade(self, data, cmap, norm=None, blend_mode='overlay', vmin=None,\n-              vmax=None, vert_exag=1, dx=1, dy=1, fraction=1, **kwargs):\n-        \"\"\"\n-        Combine colormapped data values with an illumination intensity map\n-        (a.k.a.  \"hillshade\") of the values.\n-\n-        Parameters\n-        ----------\n-        data : 2D array-like\n-            The height values used to generate a shaded map.\n-        cmap : `~matplotlib.colors.Colormap`\n-            The colormap used to color the *data* array. Note that this must be\n-            a `~matplotlib.colors.Colormap` instance.  For example, rather than\n-            passing in ``cmap='gist_earth'``, use\n-            ``cmap=plt.get_cmap('gist_earth')`` instead.\n-        norm : `~matplotlib.colors.Normalize` instance, optional\n-            The normalization used to scale values before colormapping. If\n-            None, the input will be linearly scaled between its min and max.\n-        blend_mode : {'hsv', 'overlay', 'soft'} or callable, optional\n-            The type of blending used to combine the colormapped data\n-            values with the illumination intensity.  Default is\n-            \"overlay\".  Note that for most topographic surfaces,\n-            \"overlay\" or \"soft\" appear more visually realistic. If a\n-            user-defined function is supplied, it is expected to\n-            combine an MxNx3 RGB array of floats (ranging 0 to 1) with\n-            an MxNx1 hillshade array (also 0 to 1).  (Call signature\n-            ``func(rgb, illum, **kwargs)``) Additional kwargs supplied\n-            to this function will be passed on to the *blend_mode*\n-            function.\n-        vmin : float or None, optional\n-            The minimum value used in colormapping *data*. If *None* the\n-            minimum value in *data* is used. If *norm* is specified, then this\n-            argument will be ignored.\n-        vmax : float or None, optional\n-            The maximum value used in colormapping *data*. If *None* the\n-            maximum value in *data* is used. If *norm* is specified, then this\n-            argument will be ignored.\n-        vert_exag : number, optional\n-            The amount to exaggerate the elevation values by when calculating\n-            illumination. This can be used either to correct for differences in\n-            units between the x-y coordinate system and the elevation\n-            coordinate system (e.g. decimal degrees vs. meters) or to\n-            exaggerate or de-emphasize topography.\n-        dx : number, optional\n-            The x-spacing (columns) of the input *elevation* grid.\n-        dy : number, optional\n-            The y-spacing (rows) of the input *elevation* grid.\n-        fraction : number, optional\n-            Increases or decreases the contrast of the hillshade.  Values\n-            greater than one will cause intermediate values to move closer to\n-            full illumination or shadow (and clipping any values that move\n-            beyond 0 or 1). Note that this is not visually or mathematically\n-            the same as vertical exaggeration.\n-        Additional kwargs are passed on to the *blend_mode* function.\n-\n-        Returns\n-        -------\n-        `~numpy.ndarray`\n-            An MxNx4 array of floats ranging between 0-1.\n-        \"\"\"\n-        if vmin is None:\n-            vmin = data.min()\n-        if vmax is None:\n-            vmax = data.max()\n-        if norm is None:\n-            norm = Normalize(vmin=vmin, vmax=vmax)\n-\n-        rgb0 = cmap(norm(data))\n-        rgb1 = self.shade_rgb(rgb0, elevation=data, blend_mode=blend_mode,\n-                              vert_exag=vert_exag, dx=dx, dy=dy,\n-                              fraction=fraction, **kwargs)\n-        # Don't overwrite the alpha channel, if present.\n-        rgb0[..., :3] = rgb1[..., :3]\n-        return rgb0\n-\n-    def shade_rgb(self, rgb, elevation, fraction=1., blend_mode='hsv',\n-                  vert_exag=1, dx=1, dy=1, **kwargs):\n-        \"\"\"\n-        Use this light source to adjust the colors of the *rgb* input array to\n-        give the impression of a shaded relief map with the given *elevation*.\n-\n-        Parameters\n-        ----------\n-        rgb : array-like\n-            An (M, N, 3) RGB array, assumed to be in the range of 0 to 1.\n-        elevation : array-like\n-            An (M, N) array of the height values used to generate a shaded map.\n-        fraction : number\n-            Increases or decreases the contrast of the hillshade.  Values\n-            greater than one will cause intermediate values to move closer to\n-            full illumination or shadow (and clipping any values that move\n-            beyond 0 or 1). Note that this is not visually or mathematically\n-            the same as vertical exaggeration.\n-        blend_mode : {'hsv', 'overlay', 'soft'} or callable, optional\n-            The type of blending used to combine the colormapped data values\n-            with the illumination intensity.  For backwards compatibility, this\n-            defaults to \"hsv\". Note that for most topographic surfaces,\n-            \"overlay\" or \"soft\" appear more visually realistic. If a\n-            user-defined function is supplied, it is expected to combine an\n-            MxNx3 RGB array of floats (ranging 0 to 1) with an MxNx1 hillshade\n-            array (also 0 to 1).  (Call signature\n-            ``func(rgb, illum, **kwargs)``)\n-            Additional kwargs supplied to this function will be passed on to\n-            the *blend_mode* function.\n-        vert_exag : number, optional\n-            The amount to exaggerate the elevation values by when calculating\n-            illumination. This can be used either to correct for differences in\n-            units between the x-y coordinate system and the elevation\n-            coordinate system (e.g. decimal degrees vs. meters) or to\n-            exaggerate or de-emphasize topography.\n-        dx : number, optional\n-            The x-spacing (columns) of the input *elevation* grid.\n-        dy : number, optional\n-            The y-spacing (rows) of the input *elevation* grid.\n-        Additional kwargs are passed on to the *blend_mode* function.\n-\n-        Returns\n-        -------\n-        `~numpy.ndarray`\n-            An (m, n, 3) array of floats ranging between 0-1.\n-        \"\"\"\n-        # Calculate the \"hillshade\" intensity.\n-        intensity = self.hillshade(elevation, vert_exag, dx, dy, fraction)\n-        intensity = intensity[..., np.newaxis]\n-\n-        # Blend the hillshade and rgb data using the specified mode\n-        lookup = {\n-                'hsv': self.blend_hsv,\n-                'soft': self.blend_soft_light,\n-                'overlay': self.blend_overlay,\n-                }\n-        if blend_mode in lookup:\n-            blend = lookup[blend_mode](rgb, intensity, **kwargs)\n-        else:\n-            try:\n-                blend = blend_mode(rgb, intensity, **kwargs)\n-            except TypeError as err:\n-                raise ValueError('\"blend_mode\" must be callable or one of '\n-                                 f'{lookup.keys}') from err\n-\n-        # Only apply result where hillshade intensity isn't masked\n-        if np.ma.is_masked(intensity):\n-            mask = intensity.mask[..., 0]\n-            for i in range(3):\n-                blend[..., i][mask] = rgb[..., i][mask]\n-\n-        return blend\n-\n-    def blend_hsv(self, rgb, intensity, hsv_max_sat=None, hsv_max_val=None,\n-                  hsv_min_val=None, hsv_min_sat=None):\n-        \"\"\"\n-        Take the input data array, convert to HSV values in the given colormap,\n-        then adjust those color values to give the impression of a shaded\n-        relief map with a specified light source.  RGBA values are returned,\n-        which can then be used to plot the shaded image with imshow.\n-\n-        The color of the resulting image will be darkened by moving the (s, v)\n-        values (in HSV colorspace) toward (hsv_min_sat, hsv_min_val) in the\n-        shaded regions, or lightened by sliding (s, v) toward (hsv_max_sat,\n-        hsv_max_val) in regions that are illuminated.  The default extremes are\n-        chose so that completely shaded points are nearly black (s = 1, v = 0)\n-        and completely illuminated points are nearly white (s = 0, v = 1).\n-\n-        Parameters\n-        ----------\n-        rgb : `~numpy.ndarray`\n-            An MxNx3 RGB array of floats ranging from 0 to 1 (color image).\n-        intensity : `~numpy.ndarray`\n-            An MxNx1 array of floats ranging from 0 to 1 (grayscale image).\n-        hsv_max_sat : number, default: 1\n-            The maximum saturation value that the *intensity* map can shift the\n-            output image to.\n-        hsv_min_sat : number, optional\n-            The minimum saturation value that the *intensity* map can shift the\n-            output image to. Defaults to 0.\n-        hsv_max_val : number, optional\n-            The maximum value (\"v\" in \"hsv\") that the *intensity* map can shift\n-            the output image to. Defaults to 1.\n-        hsv_min_val : number, optional\n-            The minimum value (\"v\" in \"hsv\") that the *intensity* map can shift\n-            the output image to. Defaults to 0.\n-\n-        Returns\n-        -------\n-        `~numpy.ndarray`\n-            An MxNx3 RGB array representing the combined images.\n-        \"\"\"\n-        # Backward compatibility...\n-        if hsv_max_sat is None:\n-            hsv_max_sat = self.hsv_max_sat\n-        if hsv_max_val is None:\n-            hsv_max_val = self.hsv_max_val\n-        if hsv_min_sat is None:\n-            hsv_min_sat = self.hsv_min_sat\n-        if hsv_min_val is None:\n-            hsv_min_val = self.hsv_min_val\n-\n-        # Expects a 2D intensity array scaled between -1 to 1...\n-        intensity = intensity[..., 0]\n-        intensity = 2 * intensity - 1\n-\n-        # Convert to rgb, then rgb to hsv\n-        hsv = rgb_to_hsv(rgb[:, :, 0:3])\n-        hue, sat, val = np.moveaxis(hsv, -1, 0)\n-\n-        # Modify hsv values (in place) to simulate illumination.\n-        # putmask(A, mask, B) <=> A[mask] = B[mask]\n-        np.putmask(sat, (np.abs(sat) > 1.e-10) & (intensity > 0),\n-                   (1 - intensity) * sat + intensity * hsv_max_sat)\n-        np.putmask(sat, (np.abs(sat) > 1.e-10) & (intensity < 0),\n-                   (1 + intensity) * sat - intensity * hsv_min_sat)\n-        np.putmask(val, intensity > 0,\n-                   (1 - intensity) * val + intensity * hsv_max_val)\n-        np.putmask(val, intensity < 0,\n-                   (1 + intensity) * val - intensity * hsv_min_val)\n-        np.clip(hsv[:, :, 1:], 0, 1, out=hsv[:, :, 1:])\n-\n-        # Convert modified hsv back to rgb.\n-        return hsv_to_rgb(hsv)\n-\n-    def blend_soft_light(self, rgb, intensity):\n-        \"\"\"\n-        Combine an RGB image with an intensity map using \"soft light\" blending,\n-        using the \"pegtop\" formula.\n-\n-        Parameters\n-        ----------\n-        rgb : `~numpy.ndarray`\n-            An MxNx3 RGB array of floats ranging from 0 to 1 (color image).\n-        intensity : `~numpy.ndarray`\n-            An MxNx1 array of floats ranging from 0 to 1 (grayscale image).\n-\n-        Returns\n-        -------\n-        `~numpy.ndarray`\n-            An MxNx3 RGB array representing the combined images.\n-        \"\"\"\n-        return 2 * intensity * rgb + (1 - 2 * intensity) * rgb**2\n-\n-    def blend_overlay(self, rgb, intensity):\n-        \"\"\"\n-        Combine an RGB image with an intensity map using \"overlay\" blending.\n-\n-        Parameters\n-        ----------\n-        rgb : `~numpy.ndarray`\n-            An MxNx3 RGB array of floats ranging from 0 to 1 (color image).\n-        intensity : `~numpy.ndarray`\n-            An MxNx1 array of floats ranging from 0 to 1 (grayscale image).\n-\n-        Returns\n-        -------\n-        ndarray\n-            An MxNx3 RGB array representing the combined images.\n-        \"\"\"\n-        low = 2 * intensity * rgb\n-        high = 1 - 2 * (1 - intensity) * (1 - rgb)\n-        return np.where(rgb <= 0.5, low, high)\n-\n-\n-def from_levels_and_colors(levels, colors, extend='neither'):\n-    \"\"\"\n-    A helper routine to generate a cmap and a norm instance which\n-    behave similar to contourf's levels and colors arguments.\n-\n-    Parameters\n-    ----------\n-    levels : sequence of numbers\n-        The quantization levels used to construct the `BoundaryNorm`.\n-        Value ``v`` is quantized to level ``i`` if ``lev[i] <= v < lev[i+1]``.\n-    colors : sequence of colors\n-        The fill color to use for each level. If *extend* is \"neither\" there\n-        must be ``n_level - 1`` colors. For an *extend* of \"min\" or \"max\" add\n-        one extra color, and for an *extend* of \"both\" add two colors.\n-    extend : {'neither', 'min', 'max', 'both'}, optional\n-        The behaviour when a value falls out of range of the given levels.\n-        See `~.Axes.contourf` for details.\n-\n-    Returns\n-    -------\n-    cmap : `~matplotlib.colors.Normalize`\n-    norm : `~matplotlib.colors.Colormap`\n-    \"\"\"\n-    slice_map = {\n-        'both': slice(1, -1),\n-        'min': slice(1, None),\n-        'max': slice(0, -1),\n-        'neither': slice(0, None),\n-    }\n-    _api.check_in_list(slice_map, extend=extend)\n-    color_slice = slice_map[extend]\n-\n-    n_data_colors = len(levels) - 1\n-    n_expected = n_data_colors + color_slice.start - (color_slice.stop or 0)\n-    if len(colors) != n_expected:\n-        raise ValueError(\n-            f'With extend == {extend!r} and {len(levels)} levels, '\n-            f'expected {n_expected} colors, but got {len(colors)}')\n-\n-    cmap = ListedColormap(colors[color_slice], N=n_data_colors)\n-\n-    if extend in ['min', 'both']:\n-        cmap.set_under(colors[0])\n-    else:\n-        cmap.set_under('none')\n-\n-    if extend in ['max', 'both']:\n-        cmap.set_over(colors[-1])\n-    else:\n-        cmap.set_over('none')\n-\n-    cmap.colorbar_extend = extend\n-\n-    norm = BoundaryNorm(levels, ncolors=n_data_colors)\n-    return cmap, norm\n+    def\ndiff --git a/lib/matplotlib/tests/test_colors.py b/lib/matplotlib/tests/test_colors.py\nindex 6c812529e1..b373ac3368 100644\n--- a/lib/matplotlib/tests/test_colors.py\n+++ b/lib/matplotlib/tests/test_colors.py\n@@ -522,6 +522,15 @@ def test_lognorm_invalid(vmin, vmax):\n     with pytest.raises(ValueError):\n         norm.inverse(1)\n \n+def test_lognorm_colorbar_update():\n+    \"\"\"Test LogNorm works correctly when updating after colorbar creation.\"\"\"\n+    fig, ax = plt.subplots()\n+    pcm = ax.pcolormesh([[1, 2], [3, 4]], norm=mcolors.LogNorm())\n+    fig.colorbar(pcm)\n+    pcm.set_norm(mcolors.LogNorm(vmin=2))  # Should not raise\n+    assert pcm.norm.vmin == 2\n+    plt.close(fig)\n+\n \n def test_LogNorm():\n     \"\"\"\n",
    "cost": 0,
    "edit_outcome": true,
    "lint_outcome": true,
    "test_outcome": false,
    "resolved": false
}